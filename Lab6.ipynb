{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qcritt/cosc470s24/blob/main/Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_custom_images(directory, size=(32,32)):\n",
        "    images = []\n",
        "    # List all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        # Construct the full path to the image\n",
        "        path = os.path.join(directory, filename)\n",
        "        # Open the image file\n",
        "        image = Image.open(path)\n",
        "        # Resize image (just in case some are not 32x32)\n",
        "        image = image.resize(size)\n",
        "        # Convert image to numpy array\n",
        "        image_data = np.asarray(image)\n",
        "        # Scale data to the range [-1, 1]\n",
        "        image_data = (image_data - 127.5) / 127.5\n",
        "        images.append(image_data)\n",
        "    # Convert list to a numpy array\n",
        "    images = np.array(images)\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "ZtTo84XB579p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your custom dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_custom_images(directory):\n",
        "    images = []\n",
        "    # List all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        # Construct the full path to the image\n",
        "        path = os.path.join(directory, filename)\n",
        "        # Check if the file is an image file\n",
        "        if os.path.isfile(path) and any(path.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
        "            # Open the image and append it to the list\n",
        "            image = Image.open(path)\n",
        "            images.append(image)\n",
        "    return images\n",
        "\n",
        "# Load your custom dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_custom_images(directory):\n",
        "    images = []\n",
        "    # List all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        # Construct the full path to the image\n",
        "        path = os.path.join(directory, filename)\n",
        "        # Check if the file is an image file\n",
        "        if os.path.isfile(path) and any(path.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
        "            # Open the image, convert it to numpy array, and append it to the list\n",
        "            image = Image.open(path)\n",
        "            image_array = np.array(image)\n",
        "            images.append(image_array)\n",
        "    # Convert the list of images to a numpy array\n",
        "    dataset = np.array(images)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "# Join the directory name with the current working directory\n",
        "directory = os.path.join(current_directory, 'ResizedFrames')\n"
      ],
      "metadata": {
        "id": "7y2pAfdy6sHo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "def define_discriminator(in_shape=(32, 32, 3)):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    n_nodes = 256 * 4 * 4\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((4, 4, 256)))\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rbECfVw68bwy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_gan(generator, discriminator):\n",
        "    # make weights in the discriminator not trainable\n",
        "    discriminator.trainable = False\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(generator)\n",
        "    # add the discriminator\n",
        "    model.add(discriminator)\n",
        "    # compile model\n",
        "    opt = Adam(lr=0.0001, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "bHhq0H6_8fp6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def train_gan(g_model, d_model, gan_model, dataset, latent_dim, epochs=2, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(dataset.shape[0] // batch_size):\n",
        "            # randomly select real samples\n",
        "            idx = np.random.randint(0, dataset.shape[0], half_batch)\n",
        "            real_images = dataset[idx]\n",
        "            real_y = np.ones((half_batch, 1))\n",
        "            # generate fake images\n",
        "            noise = np.random.randn(latent_dim * half_batch).reshape(half_batch, latent_dim)\n",
        "            fake_images = g_model.predict(noise)\n",
        "            fake_y = np.zeros((half_batch, 1))\n",
        "            # update discriminator model\n",
        "            d_model.train_on_batch(real_images, real_y)\n",
        "            d_model.train_on_batch(fake_images, fake_y)\n",
        "            # prepare points in latent space as input for the generator\n",
        "            x_gan = np.random.randn(latent_dim * batch_size).reshape(batch_size, latent_dim)\n",
        "            y_gan = np.ones((batch_size, 1))\n",
        "            # update the generator via the discriminator's error\n",
        "            gan_model.train_on_batch(x_gan, y_gan)\n",
        "\n",
        "            # Plot a generated image after every batch\n",
        "            if batch % 1 == 0:\n",
        "                show_generated_image(g_model, latent_dim)\n",
        "\n",
        "def show_generated_image(g_model, latent_dim):\n",
        "    noise = np.random.randn(latent_dim).reshape(1, latent_dim)\n",
        "    image = g_model.predict(noise)[0]\n",
        "    image = (image + 1) / 2.0  # Rescale to [0, 1]\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7hhJICM284Kf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100  # Dimensionality of the latent space\n",
        "\n",
        "# Define models\n",
        "discriminator = define_discriminator()\n",
        "generator = define_generator(latent_dim)\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "\n",
        "# Load dataset (assuming this is already done)\n",
        "dataset = load_custom_images('/content/')\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(generator, discriminator, gan_model, dataset, latent_dim, epochs=100, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAPGZ1uM85br",
        "outputId": "88d37450-374f-4af6-c4f3-7f3c0d5cf8ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the images quickly become black and I cant get them to show any light. I tried changing some parameter like learning rate and it didnt help."
      ],
      "metadata": {
        "id": "1ePWqlPMAF1Z"
      }
    }
  ]
}